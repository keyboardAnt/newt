#!/bin/bash
# Evaluate the latest checkpoint per task with video logging (wandb.Video).
# One array element per task listed in jobs/tasks_soup.txt.

#BSUB -J newt-eval[1-200]               # 200 jobs (one per task)
#BSUB -q "short-gpu long-gpu"           # Multi-queue: try short-gpu first (180 GPU limit)
#BSUB -n 1                              # 1 CPU core
#BSUB -gpu "num=1:mode=exclusive_process"  # 1 GPU (exclusive)
#BSUB -R "rusage[mem=16GB]"             # 16 GB RAM
#BSUB -W 04:00                          # walltime per eval job (under 6h for short-gpu)
#BSUB -o /home/projects/dharel/nadavt/repos/newt/tdmpc2/logs/lsf/newt-eval.%J.%I.log
#BSUB -e /home/projects/dharel/nadavt/repos/newt/tdmpc2/logs/lsf/newt-eval.%J.%I.log

# Run inside the Docker image (must already be built and pushed)
#BSUB -app nvidia-gpu
#BSUB -env "LSB_CONTAINER_IMAGE=ops:5000/newt:1.0.1"

cd /home/projects/dharel/nadavt/repos/newt/tdmpc2

# Ensure wandb video deps are present (moviepy, ffmpeg bindings)
pip install -q "wandb[media]"

# Select the task for this array index (1-based)
TASK=$(sed -n "${LSB_JOBINDEX}p" jobs/tasks_soup.txt)
echo "LSF job index: ${LSB_JOBINDEX}, task: ${TASK}"

# NOTE: ManiSkill tasks (87-122) require non-exclusive GPU mode.
# Submit them separately: bsub -gpu "num=1" ... for indices 87-122

# Find the latest checkpoint for this task; skip if none exists.
# Pass task via environment variable since heredoc is single-quoted
export TASK
eval $(python - <<'PY'
import os, yaml
from pathlib import Path
from discover import parse_step

task = os.environ.get("TASK", "")
logs_dir = Path("logs")
candidates = []
for run_dir in logs_dir.iterdir():
    if not run_dir.is_dir():
        continue
    run_info_path = run_dir / "run_info.yaml"
    if run_info_path.exists():
        info = yaml.safe_load(run_info_path.read_text()) or {}
        tasks = info.get("tasks", [info.get("task")])
        if task in tasks:
            for ckpt in (run_dir / "checkpoints").glob("*.pt"):
                if not ckpt.stem.endswith('_trainer'):
                    candidates.append(ckpt)
if not candidates:
    print('CKPT=')
    print('RUN_ID=')
else:
    best = max(candidates, key=parse_step)
    run_id = best.parent.parent.name
    print(f'CKPT="{best}"')
    print(f'RUN_ID="{run_id}"')
PY
)

if [ -z "${CKPT}" ]; then
  echo "No checkpoint found for task '${TASK}', skipping."
  exit 0
fi

echo "Evaluating checkpoint: ${CKPT}"

python train.py \
  task="${TASK}" \
  model_size=B \
  checkpoint="${CKPT}" \
  steps=1 \
  num_envs=2 \
  use_demos=False \
  tasks_fp=/home/projects/dharel/nadavt/tasks.json \
  exp_name="eval_${RUN_ID}" \
  save_video=True \
  env_mode=sync \
  compile=False  # Keep disabled for eval (compilation overhead > 1-step runtime)


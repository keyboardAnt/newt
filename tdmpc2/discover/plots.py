"""Visualization functions for TD-MPC2 training progress."""

from __future__ import annotations

from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Optional

if TYPE_CHECKING:
    import pandas as pd

from .progress import best_step_by_task


def require_pandas():
    try:
        import pandas as pd
    except ImportError as exc:
        raise SystemExit("pandas is required.") from exc
    return pd


def plot_max_steps(df: "pd.DataFrame", target_step: Optional[int] = None) -> None:
    """Plot the max step per task to see training progress.
    
    Args:
        df: DataFrame with all runs
        target_step: Optional target step for color coding (green=complete, orange=in progress, red=not started)
    """
    pd = require_pandas()
    import matplotlib.pyplot as plt
    
    best = best_step_by_task(df)
    if best.empty:
        print('No runs found.')
        return
    if 'max_step' not in best.columns or best['max_step'].isna().all():
        print('No step data available to plot.')
        return

    plot_df = best[['task', 'max_step']].copy().sort_values('max_step', ascending=True)
    
    n_tasks = len(plot_df)
    fig_height = max(8, n_tasks * 0.2)
    fig, ax = plt.subplots(figsize=(14, fig_height))
    bars = ax.barh(plot_df['task'], plot_df['max_step'].fillna(0))

    if target_step:
        for bar, step in zip(bars, plot_df['max_step']):
            if pd.isna(step) or step == 0:
                bar.set_color('red')
            elif step >= target_step:
                bar.set_color('green')
            else:
                bar.set_color('orange')
        ax.axvline(x=target_step, color='green', linestyle='--', linewidth=2, label=f'Target: {target_step:,}')
        ax.legend()

    ax.set_xlabel('Max training step')
    ax.set_title('Training progress per task (max step reached)')
    ax.ticklabel_format(style='plain', axis='x')
    ax.tick_params(axis='y', labelsize=8)
    plt.tight_layout()
    plt.show()


def training_overview(df: "pd.DataFrame", target_step: int = 5_000_000) -> None:
    """Generate overview statistics and visualizations for training progress.
    
    Uses the official task list from tasks.json as source of truth.
    Tasks with no runs are counted as "not started".

    Liveness is determined by `discover.liveness` (single source of truth).

    Shows 4 categories:
    - Completed: reached target_step
    - Running: incomplete but has an active signal
    - Stalled: incomplete, has progress, but no active run (needs restart)
    - Not Started: 0 steps (including tasks with no runs)
    """
    pd = require_pandas()
    import matplotlib.pyplot as plt
    from .liveness import build_task_progress
    
    # Use shared helper aligned to official task list (single source of truth: discover.liveness)
    progress = build_task_progress(df, target_step=target_step)
    
    n_tasks = len(progress)
    steps = progress['max_step']
    
    # Count by category
    completed = (progress['category'] == 'completed').sum()
    running = (progress['category'] == 'running').sum()
    stalled = (progress['category'] == 'stalled').sum()
    not_started = (progress['category'] == 'not_started').sum()
    
    pct_complete = 100 * completed / n_tasks
    avg_progress = progress['progress_pct'].mean()
    median_progress = progress['progress_pct'].median()
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # Pie chart with 4 categories
    ax1 = axes[0]
    sizes = [completed, running, stalled, not_started]
    labels = [f'Completed\n({completed})', f'Running\n({running})', f'Stalled\n({stalled})', f'Not Started\n({not_started})']
    colors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c']  # green, blue, orange, red
    explode = (0.05, 0, 0, 0)
    
    # Filter out zero-sized wedges for cleaner display
    non_zero = [(s, l, c, e) for s, l, c, e in zip(sizes, labels, colors, explode) if s > 0]
    if non_zero:
        sizes_nz, labels_nz, colors_nz, explode_nz = zip(*non_zero)
        ax1.pie(sizes_nz, labels=labels_nz, colors=colors_nz, explode=explode_nz,
            autopct='%1.1f%%', startangle=90, textprops={'fontsize': 10})
    ax1.set_title('Task Status Breakdown')
    
    # Cumulative progress
    ax2 = axes[1]
    sorted_progress = progress['progress_pct'].sort_values().reset_index(drop=True)
    ax2.fill_between(range(len(sorted_progress)), sorted_progress, alpha=0.3, color='steelblue')
    ax2.plot(sorted_progress.values, color='steelblue', linewidth=2)
    ax2.axhline(y=100, color='green', linestyle='--', linewidth=2, label='100% (Target)')
    ax2.set_xlabel('Task rank (sorted by progress)')
    ax2.set_ylabel('Progress (%)')
    ax2.set_title('Cumulative Progress Distribution')
    ax2.set_ylim(0, 110)
    ax2.legend(loc='lower right')
    
    plt.tight_layout()
    plt.show()
    
    print("=" * 60)
    print(f"{'TRAINING PROGRESS SUMMARY':^60}")
    print("=" * 60)
    print(f"  Total tasks:         {n_tasks:>6}  (from tasks.json)")
    print(f"  Target step:         {target_step:>6,}")
    print("-" * 60)
    print(f"  üü¢ ‚úÖ Completed:      {completed:>6} ({pct_complete:.1f}%)")
    print(f"  üîµ üèÉ Running:        {running:>6} ({100*running/n_tasks:.1f}%)  <- active (see discover.liveness)")
    print(f"  üü† ‚è∏Ô∏è  Stalled:        {stalled:>6} ({100*stalled/n_tasks:.1f}%)  <- needs restart")
    print(f"  üî¥ ‚ùå Not Started:    {not_started:>6} ({100*not_started/n_tasks:.1f}%)")
    print("-" * 60)
    print(f"  Average progress:    {avg_progress:>6.1f}%")
    print(f"  Median progress:     {median_progress:>6.1f}%")
    print(f"  Min steps:           {int(steps.min()):>6,}")
    print(f"  Max steps:           {int(steps.max()):>6,}")
    print("=" * 60)
    
    # Warn about unknown tasks if any (print full list)
    n_unknown = progress.attrs.get('n_unknown', 0)
    if n_unknown > 0:
        unknown = progress.attrs.get('unknown_tasks', [])
        print(f"\n  ‚ö†Ô∏è  {n_unknown} unknown tasks in runs (not in tasks.json):")
        for t in unknown:
            print(f"     - {t}")


def tasks_needing_attention(df: "pd.DataFrame", target_step: int = 5_000_000, bottom_n: int = 20) -> None:
    """Show tasks that may need attention: not started, crashed, or significantly behind."""
    pd = require_pandas()
    
    best = best_step_by_task(df)
    if best.empty:
        print('No runs found.')
        return
    
    steps = best['max_step'].fillna(0)
    not_started = best[steps == 0][['task', 'max_step']].copy()
    
    in_progress = best[(steps > 0) & (steps < target_step)].copy()
    behind = in_progress.nsmallest(bottom_n, 'max_step')[['task', 'max_step']].copy()
    behind['progress'] = (100 * behind['max_step'] / target_step).round(1).astype(str) + '%'
    
    print("=" * 70)
    print(f"{'TASKS REQUIRING ATTENTION':^70}")
    print("=" * 70)
    
    if not not_started.empty:
        print(f"\n‚ùå NOT STARTED ({len(not_started)} tasks):")
        print("-" * 70)
        for task in not_started['task'].tolist():
            print(f"   ‚Ä¢ {task}")
    else:
        print("\n‚úÖ All tasks have started training!")
    
    if not behind.empty:
        print(f"\nüê¢ LAGGING TASKS (bottom {len(behind)} by progress):")
        print("-" * 70)
        for _, row in behind.iterrows():
            steps_str = f"{int(row['max_step']):,}"
            print(f"   ‚Ä¢ {row['task']:<45} {steps_str:>12} ({row['progress']})")
    
    if 'updated_at' in best.columns:
        try:
            best_copy = best.copy()
            best_copy['updated_at_dt'] = pd.to_datetime(best_copy['updated_at'], errors='coerce')
            cutoff = datetime.now() - pd.Timedelta(hours=24)
            recent = best_copy[best_copy['updated_at_dt'] > cutoff]
            if len(recent) > 0:
                print(f"\nüìä RECENT ACTIVITY: {len(recent)} tasks updated in last 24 hours")
        except Exception:
            pass
    
    print("\n" + "=" * 70)


def progress_by_domain(df: "pd.DataFrame", target_step: int = 5_000_000) -> None:
    """Group tasks by domain prefix and show aggregate progress.
    
    Uses tasks.json as the source of truth for task list (via build_task_progress),
    so domains include not-started tasks and exclude unknown tasks by default.

    Liveness is determined by `discover.liveness` (single source of truth).
    """
    pd = require_pandas()
    import matplotlib.pyplot as plt
    from .liveness import build_task_progress
    
    progress = build_task_progress(df, target_step=target_step)
    
    def get_domain(task: str) -> str:
        for sep in ['-', '_']:
            if sep in task:
                return task.split(sep)[0]
        return task
    
    progress_copy = progress.copy()
    progress_copy['domain'] = progress_copy['task'].apply(get_domain)
    progress_copy['is_complete'] = progress_copy['max_step'] >= target_step
    
    domain_stats = progress_copy.groupby('domain').agg({
        'task': 'count',
        'max_step': 'mean',
        'progress_pct': 'mean',
        'is_complete': 'sum'
    }).rename(columns={
        'task': 'n_tasks',
        'max_step': 'avg_steps',
        'progress_pct': 'avg_progress',
        'is_complete': 'n_complete'
    })
    domain_stats['completion_rate'] = 100 * domain_stats['n_complete'] / domain_stats['n_tasks']
    domain_stats = domain_stats.sort_values('avg_progress', ascending=True)
    
    fig, axes = plt.subplots(1, 2, figsize=(14, max(5, len(domain_stats) * 0.3)))
    
    ax1 = axes[0]
    colors = ['#2ecc71' if p >= 100 else '#f39c12' if p > 0 else '#e74c3c' 
              for p in domain_stats['avg_progress']]
    ax1.barh(domain_stats.index, domain_stats['avg_progress'], color=colors, edgecolor='black', alpha=0.8)
    ax1.axvline(x=100, color='green', linestyle='--', linewidth=2)
    ax1.set_xlabel('Average Progress (%)')
    ax1.set_title('Average Training Progress by Domain')
    ax1.set_xlim(0, 110)
    
    ax2 = axes[1]
    ax2.barh(domain_stats.index, domain_stats['completion_rate'], color='steelblue', edgecolor='black', alpha=0.8)
    ax2.set_xlabel('Completion Rate (%)')
    ax2.set_title('Task Completion Rate by Domain')
    ax2.set_xlim(0, 110)
    
    for i, (idx, row) in enumerate(domain_stats.iterrows()):
        ax2.text(row['completion_rate'] + 2, i, f"({int(row['n_complete'])}/{int(row['n_tasks'])})", 
                va='center', fontsize=8)
    
    plt.tight_layout()
    plt.show()
    
    print("\nDomain Summary:")
    print("-" * 80)
    print(f"{'Domain':<20} {'Tasks':>8} {'Complete':>10} {'Avg Progress':>14} {'Completion %':>14}")
    print("-" * 80)
    for idx, row in domain_stats.sort_values('avg_progress', ascending=False).iterrows():
        print(f"{idx:<20} {int(row['n_tasks']):>8} {int(row['n_complete']):>10} "
              f"{row['avg_progress']:>13.1f}% {row['completion_rate']:>13.1f}%")
    print("-" * 80)
    
    # Warn about unknown tasks excluded from tasks.json alignment (print full list)
    n_unknown = progress.attrs.get('n_unknown', 0)
    if n_unknown > 0:
        unknown = progress.attrs.get('unknown_tasks', [])
        print(f"\n‚ö†Ô∏è  {n_unknown} unknown tasks in runs (not in tasks.json):")
        for t in unknown:
            print(f"  - {t}")


def running_runs_summary(df: "pd.DataFrame", target_step: int = 5_000_000) -> "pd.DataFrame":
    """Show summary of currently running runs by task.
    
    Liveness is determined by `discover.liveness` (single source of truth).
    
    Returns a DataFrame with columns: task, running_runs, max_step, progress_pct, needs_attention
    where needs_attention indicates tasks that are incomplete but have no running runs.
    """
    pd = require_pandas()
    from .liveness import build_task_progress, attach_liveness
    from .progress import attach_max_step
    
    # Build official per-task table aligned to tasks.json (includes tasks with no runs)
    # This uses centralized liveness for is_active and category
    progress = build_task_progress(df, target_step=target_step)
    
    # Run-level data (for stale local diagnostics)
    df_with_step = attach_max_step(df) if not df.empty else df
    df_with_step = attach_liveness(df_with_step) if not df.empty else df_with_step
    
    if df.empty:
        # No runs at all: all tasks are not started and thus "need restart" in the sense of "need start"
        summary = progress[['task', 'max_step', 'progress_pct', 'wandb_running_runs', 'heartbeat_alive_runs']].copy()
        summary.rename(columns={'wandb_running_runs': 'running_runs'}, inplace=True)
        summary['stale_local_running'] = 0
        summary['is_complete'] = False
        summary['is_active'] = False
        summary['needs_restart'] = True
        summary['has_duplicates'] = False
        summary = summary.sort_values(['needs_restart', 'progress_pct'], ascending=[False, True]).reset_index(drop=True)
    else:
        # Stale local-only "running" for warning (run-level diagnostic)
        local_only_running_mask = (df_with_step['status'] == 'running') & (df_with_step['found_in'] == 'local') if 'found_in' in df_with_step.columns else pd.Series(False, index=df_with_step.index)
        stale_local_counts = df_with_step[local_only_running_mask].groupby('task').size().rename('stale_local_running')
        
        # Use liveness progress table directly (already has wandb_running_runs, heartbeat_alive_runs, is_active)
        summary = progress[['task', 'max_step', 'progress_pct', 'wandb_running_runs', 'heartbeat_alive_runs', 'is_active']].copy()
        summary.rename(columns={'wandb_running_runs': 'running_runs'}, inplace=True)
        summary['stale_local_running'] = summary['task'].map(stale_local_counts).fillna(0).astype(int)
        
        summary['is_complete'] = summary['max_step'] >= target_step
        summary['needs_restart'] = (~summary['is_complete']) & (~summary['is_active'])
        summary['has_duplicates'] = summary['running_runs'] > 1
        
        summary = summary.sort_values(['needs_restart', 'progress_pct'], ascending=[False, True]).reset_index(drop=True)
    
    # Print summary
    total_running = summary['running_runs'].sum()
    total_hb = summary['heartbeat_alive_runs'].sum()
    total_stale = summary['stale_local_running'].sum()
    tasks_with_running = (summary['is_active']).sum()
    tasks_needing_restart = summary['needs_restart'].sum()
    tasks_with_duplicates = summary['has_duplicates'].sum()
    
    print("=" * 70)
    print(f"{'RUNNING RUNS SUMMARY':^70}")
    print("=" * 70)
    print(f"  Active runs (WB):          {total_running:>6}")
    print(f"  Active runs (HB):          {total_hb:>6}")
    if total_stale > 0:
        print(f"  Stale local 'running':     {total_stale:>6}  ‚ö†Ô∏è  (local-only)")
    print(f"  Tasks with running runs:   {tasks_with_running:>6}")
    print(f"  Tasks needing restart:     {tasks_needing_restart:>6}  ‚ö†Ô∏è  (incomplete, no active signal)")
    print(f"  Tasks with stale runs:     {tasks_with_duplicates:>6}  üîÑ (>1 wandb run, from resume)")
    print("=" * 70)
    
    return summary


def tasks_needing_restart(df: "pd.DataFrame", target_step: int = 5_000_000, show_top_n: int = None) -> "pd.DataFrame":
    """Show tasks that are incomplete but have no running runs - these need to be restarted.
    
    Liveness is determined by `discover.liveness` (single source of truth).
    
    Note: This also includes tasks that have not started yet (max_step == 0 / no runs),
    since those tasks also have no active signals and require starting.
    
    Returns DataFrame of tasks needing restart, sorted by progress (highest first, to prioritize
    tasks that are closest to completion).
    """
    pd = require_pandas()
    
    summary = running_runs_summary(df, target_step=target_step)
    if summary.empty:
        return summary
    
    # Filter to tasks needing restart
    needing = summary[summary['needs_restart']].copy()
    needing = needing.sort_values('progress_pct', ascending=False)
    
    if needing.empty:
        print("\n‚úÖ All incomplete tasks have an active signal (see discover.liveness)!")
        return needing
    
    print(f"\n‚ö†Ô∏è  TASKS NEEDING RESTART ({len(needing)} tasks, no active signal; see discover.liveness):")
    print("-" * 70)
    print(f"{'Task':<40} {'Progress':>12} {'Max Step':>15} {'HB':>6} {'Wandb':>6}")
    print("-" * 70)
    
    display_df = needing.head(show_top_n) if show_top_n else needing
    for _, row in display_df.iterrows():
        step_str = f"{int(row['max_step']):,}" if row['max_step'] > 0 else "0"
        hb = int(row.get('heartbeat_alive_runs', 0)) if 'heartbeat_alive_runs' in row else 0
        wb = int(row.get('running_runs', 0)) if 'running_runs' in row else 0
        print(f"   {row['task']:<37} {row['progress_pct']:>10.1f}% {step_str:>15} {hb:>6} {wb:>6}")
    
    if show_top_n and len(needing) > show_top_n:
        print(f"   ... and {len(needing) - show_top_n} more tasks")
    
    print("-" * 70)
    
    return needing


def stale_wandb_runs(df: "pd.DataFrame") -> "pd.DataFrame":
    """Show tasks with multiple 'running' entries in wandb (typically stale runs from checkpoint resume).
    
    When a job resumes from checkpoint after preemption/SSUSP, it creates a new wandb run.
    The old run stays "running" in wandb until it times out (~5-10 min of no heartbeat).
    
    These are NOT duplicate jobs - there's only one LSF job per task. No action needed;
    the stale runs will auto-timeout.
    
    Returns DataFrame of tasks with >1 wandb run showing as "running".
    """
    pd = require_pandas()
    
    if df.empty:
        print('No runs found.')
        return pd.DataFrame()
    
    # Only trust "running" status from wandb
    has_wandb = df['found_in'].isin(['wandb', 'both']) if 'found_in' in df.columns else True
    running = df[(df['status'] == 'running') & has_wandb].copy()
    
    if running.empty:
        print("No running runs found (see discover.liveness).")
        return pd.DataFrame()
    
    # Count per task
    counts = running.groupby('task').agg({
        'wandb_run_id': 'count',
        'exp_name': lambda x: list(x),
    }).rename(columns={'wandb_run_id': 'count'})
    
    stale = counts[counts['count'] > 1].sort_values('count', ascending=False)
    
    if stale.empty:
        print("\n‚úÖ No stale wandb runs detected!")
        return stale
    
    print(f"\nüîÑ STALE WANDB RUNS ({len(stale)} tasks with >1 'running' in wandb):")
    print("   Note: These are from checkpoint resume, NOT duplicate jobs. Will auto-timeout.")
    print("-" * 70)
    print(f"{'Task':<40} {'Wandb Runs':>10}")
    print("-" * 70)
    
    for task, row in stale.iterrows():
        print(f"   {task:<37} {row['count']:>10}")
    
    print("-" * 70)
    print(f"   Stale runs (will auto-timeout): {stale['count'].sum() - len(stale)}")
    
    return stale.reset_index()


# Keep old name as alias for backwards compatibility
duplicate_running_runs = stale_wandb_runs


def stale_run_details(df: "pd.DataFrame") -> "pd.DataFrame":
    """Show detailed info about stale wandb runs from checkpoint resume.
    
    When a job resumes from checkpoint (after preemption/SSUSP), it creates a new wandb run.
    The old wandb run remains "running" until it times out (~5-10 min of no heartbeat).
    
    This function shows which runs are stale (lower step) vs active (highest step).
    NO ACTION NEEDED - stale runs will auto-timeout. There's only one LSF job per task.
    
    Returns DataFrame with all stale runs identified.
    """
    pd = require_pandas()
    from .progress import attach_max_step
    
    if df.empty:
        print('No runs found.')
        return pd.DataFrame()
    
    df_with_step = attach_max_step(df)
    
    # Only trust "running" status from wandb
    has_wandb = df_with_step['found_in'].isin(['wandb', 'both']) if 'found_in' in df_with_step.columns else True
    running = df_with_step[(df_with_step['status'] == 'running') & has_wandb].copy()
    
    if running.empty:
        print("No running runs found (see discover.liveness).")
        return pd.DataFrame()
    
    # Find tasks with multiple running runs
    task_counts = running.groupby('task').size()
    stale_tasks = task_counts[task_counts > 1].index.tolist()
    
    if not stale_tasks:
        print("\n‚úÖ No stale wandb runs detected!")
        return pd.DataFrame()
    
    # Filter to only tasks with stale runs
    stale_runs = running[running['task'].isin(stale_tasks)].copy()
    
    # For each task, identify active (highest step) vs stale (lower step)
    max_steps_per_task = stale_runs.groupby('task')['max_step'].transform('max')
    stale_runs['status_detail'] = stale_runs.apply(
        lambda row: 'ACTIVE ‚úì' if row['max_step'] == max_steps_per_task[row.name] else 'STALE ‚è≥',
        axis=1
    )
    stale_runs = stale_runs.sort_values(['task', 'max_step'], ascending=[True, False])
    
    # Select columns to display
    display_cols = ['task', 'wandb_run_id', 'exp_name', 'max_step', 'status_detail']
    available_cols = [c for c in display_cols if c in stale_runs.columns]
    result = stale_runs[available_cols].copy()
    
    # Print detailed info
    print("\n" + "=" * 90)
    print(f"{'STALE WANDB RUNS - DETAILED VIEW':^90}")
    print("=" * 90)
    print(f"  Tasks affected:        {len(stale_tasks)}")
    print(f"  Total wandb runs:      {len(stale_runs)}")
    print(f"  Stale (will timeout):  {(result['status_detail'] == 'STALE ‚è≥').sum()}")
    print("-" * 90)
    print("  ‚ÑπÔ∏è  These are from checkpoint resume after preemption/SSUSP.")
    print("  ‚ÑπÔ∏è  Only ONE LSF job exists per task. NO ACTION NEEDED.")
    print("  ‚ÑπÔ∏è  Stale runs will auto-timeout in ~5-10 min of no heartbeat.")
    print("=" * 90)
    
    for task in stale_tasks:
        task_runs = result[result['task'] == task]
        print(f"\nüìã {task}:")
        print("-" * 90)
        print(f"   {'wandb_run_id':<15} {'exp_name':<30} {'step':>12} {'status':>12}")
        print("-" * 90)
        for _, row in task_runs.iterrows():
            step_str = f"{int(row['max_step']):,}" if pd.notna(row['max_step']) else "?"
            run_id = row.get('wandb_run_id', '?')[:12] if row.get('wandb_run_id') else '?'
            exp_name = str(row.get('exp_name', '?'))[:28]
            print(f"   {run_id:<15} {exp_name:<30} {step_str:>12} {row['status_detail']:>12}")
    
    print("\n" + "=" * 90)
    print("  ‚úÖ No action required. Stale runs will be marked as crashed by wandb automatically.")
    print("=" * 90)
    
    return result


# Keep old name as alias for backwards compatibility
duplicate_run_details = stale_run_details


def currently_running_tasks(df: "pd.DataFrame", target_step: int = 5_000_000) -> "pd.DataFrame":
    """Show all tasks that have at least one running run, with progress info.
    
    Liveness is determined by `discover.liveness` (single source of truth).
    
    Returns DataFrame with task, running_runs, progress info.
    """
    pd = require_pandas()
    
    summary = running_runs_summary(df, target_step=target_step)
    if summary.empty:
        return summary
    
    # Filter to tasks with any active signal
    running = summary[summary.get('is_active', False)].copy()
    running = running.sort_values('progress_pct', ascending=True)
    
    if running.empty:
        print("\n‚ùå No tasks currently have an active signal (see discover.liveness)!")
        return running
    
    total_runs = running['running_runs'].sum()
    total_hb = running['heartbeat_alive_runs'].sum() if 'heartbeat_alive_runs' in running.columns else 0
    print(f"\nüèÉ CURRENTLY RUNNING TASKS ({len(running)} tasks):")
    print(f"   wandb running runs: {int(total_runs)} | alive heartbeats: {int(total_hb)}")
    print("-" * 70)
    print(f"{'Task':<40} {'Wandb':>6} {'HB':>6} {'Progress':>12} {'Max Step':>12}")
    print("-" * 70)
    
    for _, row in running.iterrows():
        step_str = f"{int(row['max_step']):,}" if row['max_step'] > 0 else "0"
        stale_marker = " üîÑ" if row['has_duplicates'] else ""  # Multiple wandb runs from resume
        hb = int(row.get('heartbeat_alive_runs', 0))
        print(f"   {row['task']:<37} {int(row['running_runs']):>6} {hb:>6} {row['progress_pct']:>10.1f}% {step_str:>12}{stale_marker}")
    
    print("-" * 70)
    
    return running
